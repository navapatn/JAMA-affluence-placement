{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0nCM9HCgWDnSe0gwc2YM5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"S2SOUbEM7RmZ"},"outputs":[],"source":["\n","formula_high_adi = 'High_ADI_Placement ~ C(gndr, Treatment(reference=\"F\")) + \\\n","           C(pri_spec_grouped, Treatment(reference=\"Primary Care\")) + \\\n","           top20_institution + Log_Total_Population'\n","\n","model_high_adi_2015 = smf.logit(formula=formula_high_adi, data=cohort_2015)\n","result_high_adi_2015 = model_high_adi_2015.fit()\n","print(\"Logistic Regression Results for High ADI Placement (2015 Cohort):\")\n","print(result_high_adi_2015.summary())\n","\n","params_2015 = result_high_adi_2015.params\n","conf_2015 = result_high_adi_2015.conf_int()\n","conf_2015['Odds_Ratio'] = params_2015\n","conf_2015.columns = ['2.5%', '97.5%', 'Odds_Ratio']\n","conf_2015['Odds_Ratio'] = np.exp(conf_2015['Odds_Ratio'])\n","conf_2015['2.5%'] = np.exp(conf_2015['2.5%'])\n","conf_2015['97.5%'] = np.exp(conf_2015['97.5%'])\n","print(\"\\nOdds Ratios and 95% Confidence Intervals for 2015 Cohort:\")\n","print(conf_2015)\n","\n","\n","\n","\n","model_high_adi_2020 = smf.logit(formula=formula_high_adi, data=cohort_2020)\n","result_high_adi_2020 = model_high_adi_2020.fit()\n","print(\"\\nLogistic Regression Results for High ADI Placement (2020 Cohort):\")\n","print(result_high_adi_2020.summary())\n","\n","\n","params_2020 = result_high_adi_2020.params\n","conf_2020 = result_high_adi_2020.conf_int()\n","conf_2020['Odds_Ratio'] = params_2020\n","conf_2020.columns = ['2.5%', '97.5%', 'Odds_Ratio']\n","conf_2020['Odds_Ratio'] = np.exp(conf_2020['Odds_Ratio'])\n","conf_2020['2.5%'] = np.exp(conf_2020['2.5%'])\n","conf_2020['97.5%'] = np.exp(conf_2020['97.5%'])\n","print(\"\\nOdds Ratios and 95% Confidence Intervals for 2020 Cohort:\")\n","print(conf_2020)\n"]},{"cell_type":"markdown","source":["Logistic by specs"],"metadata":{"id":"Cqfky45Y7Ztn"}},{"cell_type":"markdown","source":[],"metadata":{"id":"cu0RgiFW7cLr"}},{"cell_type":"code","source":["# List of unique specializations\n","specializations = cohort_2015['pri_spec_grouped'].unique()\n","\n","# Iterate over each specialization\n","for spec in specializations:\n","    # Filter data for the specialization\n","    data_spec = cohort_2015[cohort_2015['pri_spec_grouped'] == spec]\n","\n","    # Ensure sufficient sample size\n","    if len(data_spec) < 50:\n","        print(f\"Skipping {spec} due to insufficient data.\")\n","        continue\n","\n","    # Define formula without 'pri_spec_grouped' since it's constant\n","    formula_spec = 'High_ADI_Placement ~ C(gndr, Treatment(reference=\"F\")) + top20_institution + Log_Total_Population'\n","\n","    # Run the logistic regression\n","    model_spec = smf.logit(formula=formula_spec, data=data_spec)\n","    try:\n","        result_spec = model_spec.fit()\n","    except Exception as e:\n","        print(f\"Could not fit model for {spec}: {e}\")\n","        continue\n","\n","    # Print the summary\n","    print(f\"\\nLogistic Regression Results for {spec} (2015 Cohort):\")\n","    print(result_spec.summary())\n","\n","    # Calculate odds ratios\n","    params_spec = result_spec.params\n","    conf_spec = result_spec.conf_int()\n","    conf_spec.columns = ['2.5%', '97.5%']\n","    odds_ratios_spec = pd.DataFrame({\n","        'Variable': params_spec.index,\n","        'OR': np.exp(params_spec),\n","        '2.5%': np.exp(conf_spec['2.5%']),\n","        '97.5%': np.exp(conf_spec['97.5%'])\n","    })\n","    print(\"\\nOdds Ratios and 95% Confidence Intervals:\")\n","    print(odds_ratios_spec)\n"],"metadata":{"id":"rhnsoULH7cbA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scipy.stats import fisher_exact\n","\n","# Create an empty list to store the results\n","state_results_2015 = []\n","\n","# Get unique states\n","states_2015 = cohort_2015['State'].unique()\n","\n","# Loop over each state\n","for state in states_2015:\n","    # Subset data for the state\n","    state_data = cohort_2015[cohort_2015['State'] == state]\n","\n","    # Create contingency table for 'top20_institution' vs. 'High_ADI_Placement'\n","    contingency_table = pd.crosstab(state_data['top20_institution'], state_data['High_ADI_Placement'])\n","\n","    # Ensure the table has both levels of 'top20_institution' and 'High_ADI_Placement'\n","    if contingency_table.shape == (2, 2):\n","        # Calculate odds ratio and p-value\n","        # Using statsmodels for odds ratio and confidence intervals\n","        ct = sm.stats.Table2x2(contingency_table.values)\n","        oddsratio = ct.oddsratio\n","        ci_low, ci_upp = ct.oddsratio_confint()\n","        # Use Fisher's Exact Test for p-value\n","        _, p_value = fisher_exact(contingency_table)\n","\n","        # Append the results\n","        state_results_2015.append({\n","            'State': state,\n","            'odds_ratio': oddsratio,\n","            'ci_lower': ci_low,\n","            'ci_upper': ci_upp,\n","            'p_value': p_value,\n","            'n_top20': state_data['top20_institution'].sum(),\n","            'n_total': len(state_data)\n","        })\n","    else:\n","        # Skip states that do not have both levels\n","        continue\n","\n","# Create a dataframe from the results\n","state_results_df_2015 = pd.DataFrame(state_results_2015)\n","\n","# Sort the dataframe by odds ratio\n","state_results_df_2015 = state_results_df_2015.sort_values('odds_ratio')\n","\n","# Output the top 10 states with the lowest odds ratios\n","top10_states_lowest_odds_2015 = state_results_df_2015.head(20)\n","\n","print(\"Top 10 States with Lowest Odds Ratios (2015 Cohort):\")\n","print(top10_states_lowest_odds_2015[['State', 'odds_ratio', 'ci_lower', 'ci_upper', 'p_value', 'n_top20', 'n_total']])\n","\n","# For 2020 Cohort\n","print(\"\\nPerforming State-Level Analysis for 2020 Cohort...\")\n","\n","# Create an empty list to store the results\n","state_results_2020 = []\n","\n","# Get unique states\n","states_2020 = cohort_2020['State'].unique()\n","\n","# Loop over each state\n","for state in states_2020:\n","    # Subset data for the state\n","    state_data = cohort_2020[cohort_2020['State'] == state]\n","\n","    # Create contingency table for 'top20_institution' vs. 'High_ADI_Placement'\n","    contingency_table = pd.crosstab(state_data['top20_institution'], state_data['High_ADI_Placement'])\n","\n","    # Ensure the table has both levels of 'top20_institution' and 'High_ADI_Placement'\n","    if contingency_table.shape == (2, 2):\n","        # Calculate odds ratio and p-value\n","        ct = sm.stats.Table2x2(contingency_table.values)\n","        oddsratio = ct.oddsratio\n","        ci_low, ci_upp = ct.oddsratio_confint()\n","        # Use Fisher's Exact Test for p-value\n","        _, p_value = fisher_exact(contingency_table)\n","\n","        # Append the results\n","        state_results_2020.append({\n","            'State': state,\n","            'odds_ratio': oddsratio,\n","            'ci_lower': ci_low,\n","            'ci_upper': ci_upp,\n","            'p_value': p_value,\n","            'n_top20': state_data['top20_institution'].sum(),\n","            'n_total': len(state_data)\n","        })\n","    else:\n","        # Skip states that do not have both levels\n","        continue\n","\n","# Create a dataframe from the results\n","state_results_df_2020 = pd.DataFrame(state_results_2020)\n","\n","# Sort the dataframe by odds ratio\n","state_results_df_2020 = state_results_df_2020.sort_values('odds_ratio')\n","\n","# Output the top 10 states with the lowest odds ratios\n","top10_states_lowest_odds_2020 = state_results_df_2020.head(20)\n","\n","print(\"Top 10 States with Lowest Odds Ratios (2020 Cohort):\")\n","print(top10_states_lowest_odds_2020[['State', 'odds_ratio', 'ci_lower', 'ci_upper', 'p_value', 'n_top20', 'n_total']])"],"metadata":{"id":"42r8a4kh7jKL"},"execution_count":null,"outputs":[]}]}